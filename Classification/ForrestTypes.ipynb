{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification on ForestTypes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Zimin Meng\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Data loading and visualization\n",
    "\n",
    "This dataset contains 198 testing instances and 325 training instances after swaping training and testing data set,and there are 4 types of class for the data set which are 'd', 'h','s' and 'o'. This project is making  classification for different forestypes by using support vector classifier and stochastic gradient descent classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_file(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "#Renaming testing and training data set\n",
    "testing_data = read_file('training.csv')\n",
    "training_data = read_file('testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "training_data.hist(bins=50, figsize=(20,15)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 325 entries, 0 to 324\n",
      "Data columns (total 28 columns):\n",
      "class                  325 non-null object\n",
      "b1                     325 non-null int64\n",
      "b2                     325 non-null int64\n",
      "b3                     325 non-null int64\n",
      "b4                     325 non-null int64\n",
      "b5                     325 non-null int64\n",
      "b6                     325 non-null int64\n",
      "b7                     325 non-null int64\n",
      "b8                     325 non-null int64\n",
      "b9                     325 non-null int64\n",
      "pred_minus_obs_H_b1    325 non-null float64\n",
      "pred_minus_obs_H_b2    325 non-null float64\n",
      "pred_minus_obs_H_b3    325 non-null float64\n",
      "pred_minus_obs_H_b4    325 non-null float64\n",
      "pred_minus_obs_H_b5    325 non-null float64\n",
      "pred_minus_obs_H_b6    325 non-null float64\n",
      "pred_minus_obs_H_b7    325 non-null float64\n",
      "pred_minus_obs_H_b8    325 non-null float64\n",
      "pred_minus_obs_H_b9    325 non-null float64\n",
      "pred_minus_obs_S_b1    325 non-null float64\n",
      "pred_minus_obs_S_b2    325 non-null float64\n",
      "pred_minus_obs_S_b3    325 non-null float64\n",
      "pred_minus_obs_S_b4    325 non-null float64\n",
      "pred_minus_obs_S_b5    325 non-null float64\n",
      "pred_minus_obs_S_b6    325 non-null float64\n",
      "pred_minus_obs_S_b7    325 non-null float64\n",
      "pred_minus_obs_S_b8    325 non-null float64\n",
      "pred_minus_obs_S_b9    325 non-null float64\n",
      "dtypes: float64(18), int64(9), object(1)\n",
      "memory usage: 71.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>pred_minus_obs_H_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>58.021538</td>\n",
       "      <td>38.381538</td>\n",
       "      <td>61.467692</td>\n",
       "      <td>96.175385</td>\n",
       "      <td>58.098462</td>\n",
       "      <td>99.196923</td>\n",
       "      <td>85.864615</td>\n",
       "      <td>27.375385</td>\n",
       "      <td>58.880000</td>\n",
       "      <td>55.786769</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.341446</td>\n",
       "      <td>-20.004954</td>\n",
       "      <td>-1.086092</td>\n",
       "      <td>-4.375846</td>\n",
       "      <td>-21.664185</td>\n",
       "      <td>-0.979815</td>\n",
       "      <td>-4.633323</td>\n",
       "      <td>-18.996462</td>\n",
       "      <td>-1.701785</td>\n",
       "      <td>-4.229108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>11.705076</td>\n",
       "      <td>14.589516</td>\n",
       "      <td>15.003385</td>\n",
       "      <td>11.120136</td>\n",
       "      <td>10.654920</td>\n",
       "      <td>9.438789</td>\n",
       "      <td>16.642765</td>\n",
       "      <td>7.445316</td>\n",
       "      <td>8.884777</td>\n",
       "      <td>12.347445</td>\n",
       "      <td>...</td>\n",
       "      <td>8.921301</td>\n",
       "      <td>2.908311</td>\n",
       "      <td>1.054544</td>\n",
       "      <td>1.850954</td>\n",
       "      <td>3.594512</td>\n",
       "      <td>0.308081</td>\n",
       "      <td>1.054033</td>\n",
       "      <td>3.307265</td>\n",
       "      <td>1.017594</td>\n",
       "      <td>1.150070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.280000</td>\n",
       "      <td>-26.790000</td>\n",
       "      <td>-5.510000</td>\n",
       "      <td>-10.120000</td>\n",
       "      <td>-34.630000</td>\n",
       "      <td>-1.830000</td>\n",
       "      <td>-7.970000</td>\n",
       "      <td>-29.340000</td>\n",
       "      <td>-6.500000</td>\n",
       "      <td>-8.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>48.370000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.660000</td>\n",
       "      <td>-22.250000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>-5.530000</td>\n",
       "      <td>-24.220000</td>\n",
       "      <td>-1.190000</td>\n",
       "      <td>-5.410000</td>\n",
       "      <td>-21.780000</td>\n",
       "      <td>-2.360000</td>\n",
       "      <td>-4.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.560000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-19.950000</td>\n",
       "      <td>-1.030000</td>\n",
       "      <td>-4.490000</td>\n",
       "      <td>-21.040000</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>-4.670000</td>\n",
       "      <td>-18.870000</td>\n",
       "      <td>-1.650000</td>\n",
       "      <td>-4.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>64.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>-18.250000</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>-2.770000</td>\n",
       "      <td>-19.060000</td>\n",
       "      <td>-0.780000</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-16.770000</td>\n",
       "      <td>-1.030000</td>\n",
       "      <td>-3.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>86.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>-7.760000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>-12.070000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>-0.770000</td>\n",
       "      <td>-8.330000</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>-0.590000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               b1          b2          b3          b4          b5          b6  \\\n",
       "count  325.000000  325.000000  325.000000  325.000000  325.000000  325.000000   \n",
       "mean    58.021538   38.381538   61.467692   96.175385   58.098462   99.196923   \n",
       "std     11.705076   14.589516   15.003385   11.120136   10.654920    9.438789   \n",
       "min     31.000000   23.000000   47.000000   69.000000   43.000000   83.000000   \n",
       "25%     50.000000   28.000000   52.000000   89.000000   51.000000   93.000000   \n",
       "50%     57.000000   32.000000   55.000000   95.000000   54.000000   96.000000   \n",
       "75%     65.000000   43.000000   65.000000  103.000000   63.000000  103.000000   \n",
       "max    107.000000   91.000000  124.000000  141.000000  100.000000  138.000000   \n",
       "\n",
       "               b7          b8          b9  pred_minus_obs_H_b1  ...  \\\n",
       "count  325.000000  325.000000  325.000000           325.000000  ...   \n",
       "mean    85.864615   27.375385   58.880000            55.786769  ...   \n",
       "std     16.642765    7.445316    8.884777            12.347445  ...   \n",
       "min     42.000000   19.000000   45.000000             4.950000  ...   \n",
       "25%     73.000000   24.000000   54.000000            48.370000  ...   \n",
       "50%     85.000000   25.000000   57.000000            57.560000  ...   \n",
       "75%     98.000000   27.000000   60.000000            64.120000  ...   \n",
       "max    136.000000   84.000000  114.000000            86.080000  ...   \n",
       "\n",
       "       pred_minus_obs_H_b9  pred_minus_obs_S_b1  pred_minus_obs_S_b2  \\\n",
       "count           325.000000           325.000000           325.000000   \n",
       "mean             -3.341446           -20.004954            -1.086092   \n",
       "std               8.921301             2.908311             1.054544   \n",
       "min             -58.280000           -26.790000            -5.510000   \n",
       "25%              -4.660000           -22.250000            -1.750000   \n",
       "50%              -1.250000           -19.950000            -1.030000   \n",
       "75%               1.430000           -18.250000            -0.390000   \n",
       "max               9.580000            -7.760000             1.780000   \n",
       "\n",
       "       pred_minus_obs_S_b3  pred_minus_obs_S_b4  pred_minus_obs_S_b5  \\\n",
       "count           325.000000           325.000000           325.000000   \n",
       "mean             -4.375846           -21.664185            -0.979815   \n",
       "std               1.850954             3.594512             0.308081   \n",
       "min             -10.120000           -34.630000            -1.830000   \n",
       "25%              -5.530000           -24.220000            -1.190000   \n",
       "50%              -4.490000           -21.040000            -0.990000   \n",
       "75%              -2.770000           -19.060000            -0.780000   \n",
       "max               1.040000           -12.070000             0.260000   \n",
       "\n",
       "       pred_minus_obs_S_b6  pred_minus_obs_S_b7  pred_minus_obs_S_b8  \\\n",
       "count           325.000000           325.000000           325.000000   \n",
       "mean             -4.633323           -18.996462            -1.701785   \n",
       "std               1.054033             3.307265             1.017594   \n",
       "min              -7.970000           -29.340000            -6.500000   \n",
       "25%              -5.410000           -21.780000            -2.360000   \n",
       "50%              -4.670000           -18.870000            -1.650000   \n",
       "75%              -3.900000           -16.770000            -1.030000   \n",
       "max              -0.770000            -8.330000             2.580000   \n",
       "\n",
       "       pred_minus_obs_S_b9  \n",
       "count           325.000000  \n",
       "mean             -4.229108  \n",
       "std               1.150070  \n",
       "min              -8.930000  \n",
       "25%              -4.870000  \n",
       "50%              -4.150000  \n",
       "75%              -3.290000  \n",
       "max              -0.590000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 325 in training data set and 198 instances in testing data set and no missing value\n",
    "#Quickly get description of data\n",
    "training_data.info()\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number for each class, there are 136 instances in class's',105 in class'd', 46 in class'o' and 38 in class'h'. Additionally, a histogram of different class is plotted and showing that the training data set is slightly inbalance among different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s     136\n",
       "d     105\n",
       "o      46\n",
       "h      38\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Distribution for each class in both training and testing set\n",
    "training_data['class'].value_counts()\n",
    "testing_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1a59cc50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See the distribution for each class\n",
    "training_data['class'].hist()\n",
    "testing_data['class'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II. Data cleaning, checking and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all the columns with name begin with 'pred_minus_obs'\n",
    "def remove_func(dataset):\n",
    "    new_data_set = []\n",
    "    temp_set = dataset.drop('class', axis = 1)\n",
    "    for col in temp_set:\n",
    "        if not 'pred_minus_obs' in col:\n",
    "            new_data_set.append(col)\n",
    "    new_set = dataset[new_data_set]\n",
    "    class_set = dataset['class']\n",
    "    return new_set, class_set\n",
    "#Generating new training and testing data set only comprises with column of class and b1 to b9 \n",
    "train_x, train_y = remove_func(training_data)\n",
    "test_x, test_y = remove_func(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization before performing classification\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scale = scaler.fit_transform(train_x.astype(np.float64))\n",
    "test_scale = scaler.transform(test_x.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. Support Vector Classifier\n",
    "This part using SVC to complete a one-versus-one binary classification. By changing the value of hymermeters C, the best score for the model appears to be 0.924 for C=10. Therefore, SVC model with C=10 is used to make compare with SGD model in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9141414141414141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53,  0,  1,  0],\n",
       "       [ 0, 39,  0,  9],\n",
       "       [ 4,  0, 33,  0],\n",
       "       [ 1,  2,  0, 56]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create the SVC model and Fit the data to the SVC model\n",
    "svc_model = svm.SVC(kernel='linear', decision_function_shape='ovo').fit(train_scale, train_y)\n",
    "\n",
    "pred_y = svc_model.predict(test_scale)\n",
    "\n",
    "print(svc_model.score(test_scale, test_y))\n",
    "\n",
    "#showing the confusion matrix \n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53,  0,  1,  0],\n",
       "       [ 0, 39,  0,  9],\n",
       "       [ 4,  0, 33,  0],\n",
       "       [ 1,  2,  0, 56]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.SVC(C=5).fit(train_scale, train_y).score(test_scale, test_y)\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53,  0,  1,  0],\n",
       "       [ 0, 39,  0,  9],\n",
       "       [ 4,  0, 33,  0],\n",
       "       [ 1,  2,  0, 56]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.SVC(C=10).fit(train_scale, train_y).score(test_scale, test_y)\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9191919191919192"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.SVC(C=20).fit(train_scale, train_y).score(test_scale, test_y)\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. Stochastic Gradient Descent classifier\n",
    "Stochastic Gradient descent classifier is used to\n",
    "In here, we trying to find a better performanced model by taking different values on the penalty parameter alpha.\n",
    "The highest score for SGD classifier is around 0.924 with alpha equals to 0.0003. And this model is used to compared with SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9141414141414141"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sgdc = SGDClassifier(random_state=22, alpha=0.0001)\n",
    "sgdc.fit(train_scale,train_y)\n",
    "sgdc_predict_y = sgdc.predict(test_scale)\n",
    "sgdc.fit(train_scale,train_y).score(test_scale, test_y)\n",
    "\n",
    "confusion_matrix(test_y, sgdc_predict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alpha = 0.0002\n",
    "sgdc_2 = SGDClassifier(random_state=22, alpha=0.0002).fit(train_scale,train_y)\n",
    "sgdc_2.fit(train_scale,train_y).score(test_scale, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53,  0,  1,  0],\n",
       "       [ 0, 43,  0,  5],\n",
       "       [ 6,  0, 31,  0],\n",
       "       [ 0,  2,  1, 56]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alpha = 0.0003, best performance\n",
    "sgdc_3 = SGDClassifier(random_state=22, alpha=0.0003).fit(train_scale,train_y)\n",
    "sgdc_predict_3 = sgdc_3.predict(test_scale)\n",
    "\n",
    "sgdc_3.fit(train_scale,train_y).score(test_scale, test_y)\n",
    "confusion_matrix(test_y, sgdc_predict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8838383838383839"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alpha = 0.0005\n",
    "sgdc_4 = SGDClassifier(random_state=22, alpha=0.0005).fit(train_scale,train_y)\n",
    "sgdc_4.fit(train_scale,train_y).score(test_scale, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. Conclusions and overall presentation\n",
    "\n",
    "Stochastic gradient decent classifier has advantages when the training data set is large. And the result showing that support vector classifier performs better on class 'd', 'o' and stochastic gradient descent classifier performs bettern on 'h' and 's' class by comparing their f1-score. \n",
    "In general, both two models performs good but SGD is a little bit better since the weighted average score achieved 0.92 which is slightly higher than SVC's score of 0.91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          d        0.91      0.98      0.95        54\n",
      "          h        0.95      0.81      0.88        48\n",
      "          o        0.97      0.89      0.93        37\n",
      "          s        0.86      0.95      0.90        59\n",
      "\n",
      "    accuracy                           0.91       198\n",
      "   macro avg       0.92      0.91      0.91       198\n",
      "weighted avg       0.92      0.91      0.91       198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          d        0.90      0.98      0.94        54\n",
      "          h        0.96      0.90      0.92        48\n",
      "          o        0.94      0.84      0.89        37\n",
      "          s        0.92      0.95      0.93        59\n",
      "\n",
      "    accuracy                           0.92       198\n",
      "   macro avg       0.93      0.92      0.92       198\n",
      "weighted avg       0.93      0.92      0.92       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating classification_report to see different scores\n",
    "from sklearn.metrics import classification_report\n",
    "#result of SVC model\n",
    "print(classification_report(test_y, pred_y))\n",
    "#result of SGD model\n",
    "print(classification_report(test_y, sgdc_predict_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
